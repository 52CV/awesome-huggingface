# awesome-huggingface
ðŸ¤— Hugging Face eco-system

## Inference Engines
*Highly optimized inference engines implementing Transformers-compatible APIs.*

* [TurboTransformers](https://github.com/Tencent/TurboTransformers) - TurboTransformers (from Tencent) is an inference engine for transformers with fast C++ API.
* [FasterTransformer](https://github.com/NVIDIA/FasterTransformer) - FasterTransformer (from Nvidia) provides a script and recipe to run the highly optimized transformer-based encoder and decoder component on NVIDIA GPUs.
* [lightseq](https://github.com/bytedance/lightseq) - lightseq (from ByteDance) is a high performance inference library for sequence processing and generation implemented in CUDA.
